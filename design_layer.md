# 네트워크 설계
가정사항
- 털 과 날개의 유무(feature=2)에 따라, 기타, 포유류,조류(Classificatin=3)을 하는 신경모델 

## 1. 가중치(weight) 설계 


첫번째 가중치의 차원은 2차원으로 [특성, 히든 레이어의 뉴런갯수] -> [2, 10] 으로 정합니다.
```
W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))
```

마지막 가중치의 차원을 [이전 히든 레이어의 뉴런 갯수, 분류 갯수] -> [10, 3] 으로 정합니다.
```
W2 = tf.Variable(tf.random_uniform([10, 3], -1., 1.))
```

## 2. 편향(Bias)설계 
- 편향을 각각 각 레이어의 `아웃풋 갯수`로 설정합니다.

b1 은 히든 레이어의 뉴런 갯수로 : `b1 = tf.Variable(tf.zeros([10]))`
b2 는 최종 결과값 즉, 분류 갯수인 3으로 설정 : `b2 = tf.Variable(tf.zeros([3]))`


## 3. CNN 설계

참고 : http://128.46.80.28:8585/edit/3_golbin/MNIST_CNN/CNN.py

### 3.1 Conv 네트워크 
#### A. 첫번째 레이어 
tf.nn.conv2d(X, W) = [입력이미지수, 가로, 세로, 필터갯수] = [?, 28, 28, 32]
- X = 입력 이미지 차원 = eg. MNIST경우 28*28*1
- W = 커널크기 `3,3` , 입력값 X의 특성수 `1`, 필터 갯수 `32` = [3, 3, 1, 32]

#### B. 두번째 레이어 
- L2 Conv shape=(?, 14, 14, 64)
    - Pool     ->(?, 7, 7, 64)
    - Reshape  ->(?, 256)
       
W2 의 [3, 3, 32, 64] 에서 32 는 L1 에서 출력된 W1 의 마지막 차원, 필터의 크기 입니다.

### 3.2 Pool 
Pool     ->(?, 14, 14, 32)


### 3.3 Full Connect Layer
- FC 레이어: 입력값 7x7x64 -> 출력값 256

## 4. RNN 설계


## 5. GAN 설계 