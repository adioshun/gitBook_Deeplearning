# 출처

## 교재

###### 텐서플로우 첫걸음, 조르디 토레스 지음, 박해선 옮김, 한빛미디어 출판


###### 딥 러닝 제대로 시작하기, 오카타니 타카유키, 2016
- 1장 시작하며 _ 1 

- 2장 앞먹임 신경망 _ 11 
 - 2.1 유닛의 출력 13 
 - 2.2 활성화 함수 15 
 - 2.3 다층 신경망 18 
 - ~~2.4 출력층의 설계와 오차함수 21~~ 

- 3장 확률적 경사 하강법 _ 29 
 - 3.1 경사 하강법 31 
 - 3.2 확률적 경사 하강법 33 
 - 3.3 ‘미니배치’의 이용 35 
 - 3.4 일반화 성능과 과적합 36 
 - 3.5 과적합을 완화시키는 방법 38 
 - 3.6 학습을 위한 트릭 43 

- 4장 역전파법 _ 53 
 - 4.1 기울기 계산의 어려움 55 
 - 4.2 2층으로 구성된 신경망의 계산 57 
 - 4.3 다층 신경망으로 일반화 60 
 - 4.4 경사 하강법의 전체 알고리즘 63 
 - 4.5 기울기 소실 문제 68 

- 5장 자기부호하기 _ 71 
 - 5.1 개요 73 
 - 5.2 자기부호화기의 설계 74 
 - 5.3 자기부호화기의 동작 76 
 - 5.4 희소 규제화 80 
 - 5.5 데이터의 백색화 87 
 - 5.6 딥 뉴럴넷의 사전훈련 92 
 - 5.7 그 외의 자기부호화기 94 

- 6장 합성곱 tlsruda아 _ 99 
 - 6.1 단순 세포와 복잡 세포 101 
 - 6.2 전체적인 구조 104 
 - 6.3 합성곱 105 
 - 6.4 합성곱층 109 
 - 6.5 풀링층 112 
 - 6.6 정규화층 115 
 - 6.7 기울기의 계산 119 
 - 6.8 실제 예: 물체 유형 인식 121 

- 7장 재귀 신경망 _ 135 
 - 7.1 연속열 데이터의 분류 137 
 - 7.2 RNN의 구조 139 
 - 7.3 순전파 계산 142 
 - 7.4 역전파 계산 144 
 - 7.5 장·단기기억 147 
 - 7.6 입력과 출력의 연속열 길이가 다른 경우 153 

- 8장 볼츠만 머신 _ 161 
 - 8.1 데이터의 생성 모델 163 
 - 8.2 볼츠만 머신 164 
 - 8.3 깁스 샘플링 168 
 - 8.4 은닉 변수를 갖는 볼츠만 머신 170 
 - 8.5 제약 볼츠만 머신 173 
 - 8.6 RBM의 학습 176 
 - 8.7 그 외의 유닛 183 
 - 8.8 딥 빌리프 네트워크 186 
 - 8.9 딥 볼츠만 머신 188 
 - 8.10 성능 비교 191 

###### 밑바닥부터 시작하는 딥러닝, 사이토 고키, 2017
- 1장 헬로 파이썬

- 2장 퍼셉트론
 - 2.1 퍼셉트론이란? 
 - 2.2 단순한 논리 회로 
 - 2.3 퍼셉트론 구현하기 
 - 2.4 퍼셉트론의 한계 
 - 2.5 다층 퍼셉트론이 출동한다면 
 - 2.6 NAND에서 컴퓨터까지 
 - 2.7 정리 
 
- 3장 신경망
 - 3.1 퍼셉트론에서 신경망으로 
 - 3.2 활성화 함수 
 - 3.3 다차원 배열의 계산 
 - 3.4 3층 신경망 구현하기 
 - 3.5 출력층 설계하기 
 - 3.6 손글씨 숫자 인식 
 - 3.7 정리 
 
- 4장 신경망 학습
 - 4.1 데이터에서 학습한다! 
 - ~~4.2 손실 함수~~ 
 - 4.3 수치 미분 
 - 4.4 기울기 
 - 4.5 학습 알고리즘 구현하기 
 - 4.6 정리 
  
- 5장 오차역전파법
 - 5.1 계산 그래프 
 - 5.2 연쇄법칙 
 - 5.3 역전파 
 - 5.4 단순한 계층 구현하기 
 - 5.5 활성화 함수 계층 구현하기 
 - 5.6 Affine/Softmax 계층 구현하기 
 - 5.7 오차역전파법 구현하기 
 - 5.8 정리 
 
- 6장 학습 관련 기술들
 - 6.1 매개변수 갱신 
 - 6.2 가중치의 초깃값 
 - 6.3 배치 정규화 
 - 6.4 바른 학습을 위해 
 - 6.5 적절한 하이퍼파라미터 값 찾기 
 - 6.6 정리 
 
- 7장 합성곱 신경망(CNN)
 - 7.1 전체 구조 
 - 7.2 합성곱 계층 
 - 7.3 풀링 계층 
 - 7.4 합성곱/풀링 계층 구현하기 
 - 7.5 CNN 구현하기 
 - 7.6 CNN 시각화하기 
 - 7.7 대표적인 CNN 
 - 7.8 정리 
 
- 8장 딥러닝
 - 8.1 더 깊게 
 - 8.2 딥러닝의 초기 역사 
 - 8.3 더 빠르게(딥러닝 고속화) 
 - 8.4 딥러닝의 활용 
 - 8.5 딥러닝의 미래 
 - 8.6 정리 
  
부록 A Softmax-with-Loss 계층의 계산 그래프
- A.1 순전파 
- A.2 역전파 
- A.3 정리 
- 참고문헌 

## 동영상

### 모두를 위한 딥러닝\(시즌1\)

* [Youtube](https://www.youtube.com/watch?v=BS6O0zOGX4E&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm)
* [강의 웹사이트](http://hunkim.github.io/ml/)
* [질문사이트](http://qna.iamprogrammer.io/c/dev/ml)
* [요약정리](http://pythonkim.tistory.com/notice/25)



## Blog 

* [파이썬\_킴 블로그](http://pythonkim.tistory.com/category/%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0)

* [라온피플 블로그](http://laonple.blog.me/220648539191)
